{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d2276-ca2b-4ad9-8260-1875bf29b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Product in plural, e.g. \"Kühlschränke\"\n",
    "product = \"Lautsprecher\"\n",
    "\n",
    "df = pd.read_csv(f\"{product}/{product}_clean.csv\", dtype={'Vendor': str}, parse_dates=['Date'], index_col=0)\n",
    "# df = pd.read_csv(f\"{product}/{product}_first_timepoint_clean.csv\", dtype={'Vendor': str}, parse_dates=['Date'], index_col=0) # uncomment when using only first timepoint\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a949ec2",
   "metadata": {},
   "source": [
    "**1. Mean Coefficient of Variation among Vendors (excluding variation over time) of each model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99587f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coef-Var among vendors represents the coef-var for each Model & Date combination. Calculate the average coef-var_among_vendors for each Model\n",
    "avg_coef_var = df.groupby('Model')['coef_var_among_vendors'].mean().reset_index()\n",
    "avg_coef_var = avg_coef_var.rename(columns={'coef_var_among_vendors': 'mean_coef_var'})\n",
    "\n",
    "display(avg_coef_var.sort_values(by='mean_coef_var', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c215ec4",
   "metadata": {},
   "source": [
    "Rounding is needed for subsequent features, but not necessary for mean_coef_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to round prices based on 1% of the median price for each model\n",
    "def round_prices_to_one_percent(sub_df):\n",
    "    model_median_price = sub_df['Median'].iloc[0]  # Get the median price for the model\n",
    "    \n",
    "    # Calculate 1% of the median price, and round it\n",
    "    rounding_factor = model_median_price * 0.01\n",
    "    \n",
    "    if rounding_factor == 0:\n",
    "        rounding_factor = 1  # Ensure that rounding factor is at least 1\n",
    "    \n",
    "    # Round the 'Price_w/o_shipping' to the nearest multiple of the rounding_factor\n",
    "    sub_df['Price_w/o_shipping'] = (sub_df['Price_w/o_shipping'] / rounding_factor).round() * rounding_factor\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "df = df.groupby('Model', group_keys=False).apply(round_prices_to_one_percent)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf1a6",
   "metadata": {},
   "source": [
    "**2. Number of times vendors changed prices for a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d258c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data contains dates spanning more than 30 days. If no, the num_price_changes column is not meaningful and we drop it in the end\n",
    "long_timeframe = (df['Date'].max() - df['Date'].min()).days >= 30\n",
    "\n",
    "# Group by 'Model', 'Vendor' and 'Manufacturer', then calculate the number of distinct prices. Thus, we know how many different prices the vendor charged for the model throughout the dataset.\n",
    "distinct_prices = df.groupby(['Model', 'Vendor', 'Manufacturer'])['Price_w/o_shipping'].nunique().reset_index()\n",
    "\n",
    "distinct_prices.columns = ['Model', 'Vendor', 'Manufacturer', 'Distinct_Price_Count']\n",
    "price_changes = distinct_prices.copy()\n",
    "price_changes['num_price_changes'] = distinct_prices['Distinct_Price_Count'] - 1\n",
    "\n",
    "# Calculate the average number of price changes for each model (across all vendors)\n",
    "price_changes = price_changes.groupby('Model')['num_price_changes'].mean().reset_index()\n",
    "\n",
    "display(price_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff1e55",
   "metadata": {},
   "source": [
    "**3. Maximum number of offerings at the same price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a27b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Model, Date and count the occurences of value in Price_w/o_shipping\n",
    "price_counts = df.groupby(['Model', 'Date', 'Price_w/o_shipping']).size().reset_index(name='Count_of_prices')\n",
    "\n",
    "# Preparing df for next metric already\n",
    "price_counts['Min_Price'] = price_counts.groupby(['Model', 'Date'])['Price_w/o_shipping'].transform('min')\n",
    "price_counts['Is_Min_Price'] = price_counts['Price_w/o_shipping'] == price_counts['Min_Price']\n",
    "price_counts = price_counts[['Model', 'Date', 'Price_w/o_shipping', 'Count_of_prices', 'Is_Min_Price']]\n",
    "\n",
    "# Get the total number of offers per Model and Date\n",
    "offer_counts = df.groupby(['Model', 'Date']).size().reset_index(name='total_offers')\n",
    "\n",
    "# Calculate the maximum percentage of prices that are the same for each Model and Date\n",
    "same_price_pct = price_counts.groupby(['Model', 'Date'])['Count_of_prices'].apply(lambda x: x.max() / x.sum()).reset_index(name='same_price_pct')\n",
    "\n",
    "# Merge the percentage data with the total offers\n",
    "same_price_pct = pd.merge(same_price_pct, offer_counts, on=['Model', 'Date'])\n",
    "\n",
    "# Merge with manufacturer data\n",
    "manufacturer_model = df[['Model', 'Manufacturer']].drop_duplicates()\n",
    "same_price_pct = pd.merge(same_price_pct, manufacturer_model, on='Model')\n",
    "\n",
    "# Average the percentage of same prices for each model across all dates\n",
    "same_price_pct = same_price_pct.groupby(by='Model')['same_price_pct'].mean(numeric_only=False).reset_index()\n",
    "\n",
    "display(same_price_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d9c24",
   "metadata": {},
   "source": [
    "**4. Number of offerings at the cheapest price**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9313bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as same_price_pct, but filter the price_counts df to only include the minimum prices\n",
    "cheap_same_price = price_counts[price_counts['Is_Min_Price'] == True]\n",
    "\n",
    "# Rename the column to 'count_cheap_same_price'\n",
    "cheap_same_price = cheap_same_price.rename(columns={'Count_of_prices': 'count_cheap_same_price'})\n",
    "\n",
    "# Merge with manufacturer data\n",
    "cheap_same_price = pd.merge(cheap_same_price, manufacturer_model, on='Model')\n",
    "\n",
    "# Merge with total offers\n",
    "cheap_same_price = pd.merge(cheap_same_price, offer_counts, on=['Model', 'Date'])\n",
    "\n",
    "# Calculate the percentage of the cheapest price for each Model and Date\n",
    "cheap_same_price['cheapest_same_price_pct'] = cheap_same_price['count_cheap_same_price'] / cheap_same_price['total_offers']\n",
    "\n",
    "# Average the percentage of the cheapest price for each model across all dates\n",
    "cheap_same_price = cheap_same_price.groupby(by='Model')['cheapest_same_price_pct'].mean(numeric_only=False).reset_index()\n",
    "\n",
    "display(cheap_same_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91272a",
   "metadata": {},
   "source": [
    "**5. Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the entropy of prices for each model\n",
    "def calculate_entropy(prices):\n",
    "    probabilities = np.bincount(prices) / len(prices) # Each unqiue value get own bin = maximum granularity (because we rounded before)\n",
    "    return entropy(probabilities)\n",
    "\n",
    "# Group by 'Model' and calculate entropy for each group\n",
    "entropy_df = df.groupby('Model')['Price_w/o_shipping'].apply(lambda x: entropy(np.histogram(x, bins=len(x))[0], base=2)).reset_index()\n",
    "\n",
    "entropy_df.columns = ['Model', 'entropy']\n",
    "\n",
    "display(entropy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d33ea4",
   "metadata": {},
   "source": [
    "**Merging all metrics into one df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([avg_coef_var, price_changes, same_price_pct, cheap_same_price, entropy_df], axis=1)\n",
    "\n",
    "# Drop duplicate \"Model\" columns, keeping the first one\n",
    "results = results.loc[:,~results.columns.duplicated()]\n",
    "results = pd.merge(results, manufacturer_model, on='Model')\n",
    "\n",
    "# Drop the 'num_price_changes' column if the timeframe is not long enough\n",
    "if not long_timeframe:\n",
    "    results.drop(columns=['num_price_changes'], inplace=True)\n",
    "\n",
    "display(results)\n",
    "\n",
    "results.to_csv(f\"{product}/{product}_results_per_model.csv\", index=False)\n",
    "#results.to_csv(f\"{product}/{product}_first_timepoint_results.csv\", index=False) # uncomment when wanting analyzing only first timepoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
