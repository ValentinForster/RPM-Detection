{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "product = \"K체hlschr채nke\" # e.g. \"Waschmaschinen\" / \"Washing machines\" or \"K체hlschr채nke\" / \"Refrigerators\"\n",
    "only_first_timepoint = False # Set to True if only the first timepoint should be analyzed\n",
    "\n",
    "def detect_delimiter(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        sniffer = csv.Sniffer()\n",
    "        return sniffer.sniff(file.read(5000)).delimiter\n",
    "\n",
    "# To adjust for different column names in the CSV files\n",
    "column_mapping = {\n",
    "    'Model': ['Model', 'Product', 'Item'],\n",
    "    'Vendor': ['Vendor', 'Seller', 'Retailer'],\n",
    "    'Price_w/o_shipping': ['Price_w/o_shipping', 'Price', 'Cost'],\n",
    "    'Date': ['Date', 'Timestamp', 'SaleDate']\n",
    "}\n",
    "\n",
    "filename = f\"{product}/{product}.csv\"\n",
    "delimiter = detect_delimiter(filename)\n",
    "\n",
    "df = pd.read_csv(filename, sep=delimiter, dtype=str)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "for standard_name, possible_names in column_mapping.items():\n",
    "    for possible_name in possible_names:\n",
    "        if possible_name.lower() in df.columns:\n",
    "            df.rename(columns={possible_name.lower(): standard_name}, inplace=True)\n",
    "            break\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Price column correct format. If the price is already in correct format, this will have no effect\n",
    "df[\"Price_w/o_shipping\"] = (\n",
    "    df[\"Price_w/o_shipping\"]\n",
    "    .str.replace(r'[^\\d.,]', '', regex=True)  # Remove any non-numeric characters except commas and periods\n",
    "    .str.replace(\",\", \".\")                    # Replace comma with period\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Create column for manufacturer by taking first word of Model name (only if there is no Manufacturer column already in the dataset)\n",
    "if 'Manufacturer' not in df.columns:\n",
    "    df[\"Manufacturer\"] = df[\"Model\"].str.split().str[0]\n",
    "\n",
    "# Drop all columns except the ones we need\n",
    "df = df[['Model','Price_w/o_shipping','Vendor', 'Manufacturer', 'Date']]\n",
    "print(f\"Initial number of rows: {len(df)}\")\n",
    "\n",
    "# Drop rows with NA\n",
    "df = df.dropna()\n",
    "print(f\"After dropping NA: {len(df)}\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_first_timepoint:    \n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y %H:%M')\n",
    "    #earliest_timestamp = df['Date'].min()\n",
    "    target_date = pd.to_datetime('09.11.2022 18:00', format='%d.%m.%Y %H:%M') # change depending on dataset\n",
    "    df = df[df['Date'] == target_date]\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2aee12-bf9b-4f91-9743-de6dc655f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where Manufacturer name is in Vendor (meaning that the vendor is a store operated by the manufacturer). No RPM possible when vendor and manufacturer is the same company\n",
    "df['Manufacturer'] = df['Manufacturer'].astype(str)\n",
    "df['Vendor'] = df['Vendor'].astype(str)\n",
    "df = df[~df.apply(lambda row: row['Manufacturer'] in row['Vendor'], axis=1)]\n",
    "print(f\"After dropping offers by the manufacturer themselves: {len(df)}\")\n",
    "\n",
    "# Convert all vendors to lowercase, to avoid one vendor being counted multiple times because of capitalization differences\n",
    "df['Vendor'] = df['Vendor'].apply(lambda x: x.lower())\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"After dropping duplicates: {len(df)}\")\n",
    "\n",
    "# Exclude rows where the same vendor offers the same model at the same date for different prices (there may be variants of the model, like different colors). Keep the lowest price\n",
    "idx = df.groupby(['Model', 'Vendor', 'Date'])['Price_w/o_shipping'].idxmin()\n",
    "df = df.loc[idx].reset_index(drop=True)\n",
    "print(f\"After dropping variants of each model: {len(df)}\")\n",
    "\n",
    "# Calculate the number of vendors for each product\n",
    "df[\"Count_vendors\"] = df.groupby([\"Model\", \"Date\"])[\"Model\"].transform(\"count\")\n",
    "\n",
    "# Add median, std, mean and coef_var per distinct model and date pair.\n",
    "df_grouped = df.groupby(['Model', 'Date']).agg(Median=('Price_w/o_shipping', 'median'), Std=('Price_w/o_shipping', 'std'), Mean=('Price_w/o_shipping', 'mean')).reset_index()\n",
    "df = df.merge(df_grouped, on=[\"Model\",\"Date\"])\n",
    "\n",
    "# Add Price_ratio (ratio of the price of the offering compared to the median & mean price)\n",
    "df['Price_ratio_median'] = df['Price_w/o_shipping'] / df['Median']\n",
    "df['Price_ratio_mean'] = df['Price_w/o_shipping'] / df['Mean']\n",
    "\n",
    "# Remove outliers (50% above median, 50% below median) --> if there are many timepoints in the dataset, this will remove a lot of data, as a typo by the vendor is removed multiple times\n",
    "df = df[df['Price_ratio_median'] <= 1.5]\n",
    "print(f\"After removing outliers double the median price: {len(df)}\")\n",
    "df = df[df['Price_ratio_median'] > 0.5]\n",
    "print(f\"After removing outliers half the median price: {len(df)}\")\n",
    "\n",
    "# Print counts of distinct vendors, models and manufacturers remaining in the dataset\n",
    "num_vendors = df['Vendor'].nunique()\n",
    "num_models = df['Model'].nunique()\n",
    "num_hersteller = df['Manufacturer'].nunique()\n",
    "print(f\"Before Amthauer filtering, the dataset had {len(df)} rows, {num_vendors} vendors, {num_models} models from {num_hersteller} manufacturers\")\n",
    "\n",
    "# ------------------------------------------------------------- Default settings of Amthauer et al. (2023) (excl. 3 Model rule) -----------------------------------------------------------------------------------\n",
    "\n",
    "# \"We only include a model at one point in time if at this time it was offered by at least 5 vendors, to ensure that variation is generally possible.\" ------------------------------------------------------------\n",
    "df = df[df['Count_vendors'] >= 5]\n",
    "print(f\"After 5 Vendor filtering, the dataset had {len(df)} rows\")\n",
    "\n",
    "# Remove models, which are not offered at at least 75% of all distinct timepoints (only if not too much data is removed) ------------------------------------------------------------------------------------------\n",
    "\n",
    "# Calculate the total number of unique dates\n",
    "total_unique_dates = df['Date'].nunique()\n",
    "\n",
    "# Calculate 75% of the total number of unique dates\n",
    "threshold_75 = 0.75 * total_unique_dates\n",
    "\n",
    "# Group by model Model and count unique dates for each model\n",
    "model_date_counts = df.groupby('Model')['Date'].nunique()\n",
    "\n",
    "# Remove models that appear in less than 75% of all distinct dates\n",
    "below75_models = model_date_counts[model_date_counts < threshold_75].index.tolist()\n",
    "\n",
    "# If user uploads data spanning multiple product categories scraped on different dates, this would remove most data. Hence, this checks if much data would be removed. If yes, skip this step.\n",
    "if len(below75_models) * 0.25 < len(df):\n",
    "    df = df[~df['Model'].isin(below75_models)]\n",
    "    print(f\"After 75% timepoints filtering, the dataset had {len(df)} rows ----------------------\")\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Calculate the variance per model and timepoint pair across vendors. Calculate coef-var for each Model & Date combination\n",
    "vendor_var = df.groupby(['Model', 'Date'])['Price_w/o_shipping'].agg(['mean', 'std', 'nunique']).reset_index()\n",
    "vendor_var['coef_var_among_vendors'] = vendor_var['std'] / vendor_var['mean']\n",
    "vendor_var.rename(columns={\"mean\": \"mean_among_vendors\", 'std': 'std_among_vendors', 'nunique': 'distinct_vendor_prices'}, inplace=True)\n",
    "df = df.merge(vendor_var, on=[\"Model\",\"Date\"])\n",
    "\n",
    "# Drop rows with NA (just in case any NA were created during the previous steps)\n",
    "df = df.dropna()\n",
    "print(f\"After dropping NA: {len(df)}\")\n",
    "\n",
    "# Reorder columns\n",
    "new_column_order = ['Model',\n",
    "                    'Price_w/o_shipping',\n",
    "                    'Vendor',\n",
    "                    'Count_vendors',\n",
    "                    'Manufacturer',\n",
    "                    'Date',\n",
    "                    'Median',\n",
    "                    'Mean',\n",
    "                    'Std',\n",
    "                    'Price_ratio_median',\n",
    "                    'Price_ratio_mean',\n",
    "                    'distinct_vendor_prices',\n",
    "                    'mean_among_vendors',\n",
    "                    'std_among_vendors',\n",
    "                    'coef_var_among_vendors']\n",
    "\n",
    "df = df.reindex(columns=new_column_order)\n",
    "\n",
    "# Get counts of distinct vendors, models and manufacturers again, to compare the numbers before and after cleaning\n",
    "num_vendors = df['Vendor'].nunique()\n",
    "num_models = df['Model'].nunique()\n",
    "num_hersteller = df['Manufacturer'].nunique()\n",
    "\n",
    "print(f\"The dataset now has {len(df)} rows, {num_vendors} vendors, {num_models} models from {num_hersteller} manufacturers\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559994f9-0efa-40d4-bdcf-651f81a22ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "if only_first_timepoint:\n",
    "    df.to_csv(f\"{product}/{product}_first_timepoint_clean.csv\")\n",
    "else:\n",
    "    df.to_csv(f\"{product}/{product}_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
